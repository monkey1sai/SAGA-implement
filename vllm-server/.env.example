# ==================================================
# vLLM Server 環境變數配置
# 複製此檔案為 .env 並填入實際值
# ==================================================

# -------------------- API 安全 --------------------
# vLLM API 金鑰 (必填，用於 API 認證)
VLLM_API_KEY=your-secure-api-key-here

# HuggingFace Token (部分模型需要，如 Llama 系列)
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxx

# -------------------- 模型配置 --------------------
# 模型名稱 (HuggingFace 格式)
# RTX 4060 Ti 8GB 推薦模型:
#   - Qwen/Qwen2.5-3B-Instruct (預設，約 6GB VRAM)
#   - microsoft/Phi-3-mini-4k-instruct (約 5GB VRAM)
#   - TheBloke/Mistral-7B-Instruct-v0.2-GPTQ (量化版，約 5GB VRAM)
#   - Qwen/Qwen2.5-1.5B-Instruct (約 3GB VRAM，輕量版)
MODEL_NAME=Qwen/Qwen2.5-3B-Instruct

# 最大上下文長度 (RTX 4060 Ti 8GB 建議 2048-4096)
MAX_MODEL_LEN=4096

# 模型快取路徑 (Windows 格式需調整)
MODEL_CACHE_PATH=~/.cache/huggingface

# -------------------- Grafana (監控用) --------------------
GRAFANA_USER=admin
GRAFANA_PASSWORD=your-grafana-password
